{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Image Processing in Python\n",
    "\n",
    "## A concrete application in histopathology\n",
    "\n",
    "#### Quentin Caudron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is histopathology ?\n",
    "\n",
    "> Histopathology is the microscopic examination of tissue samples (from biopsies), to study manifestations of disease.\n",
    "\n",
    "&mdash; Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"talk/histopathology.jpg\" width=\"800px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Preparation of tissue samples\n",
    "\n",
    "The tissue is *processed* by embedding in paraffin wax, microtomy, and staining with dyes.\n",
    "\n",
    "<img src=\"talk/histopathology_prep.jpg\" width=\"800px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Traditionally, analysis often relies on scores\n",
    "\n",
    "<img src=\"talk/experiment.jpg\" width=\"800px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Problems : manual scoring doesn't capture everything\n",
    "\n",
    "<img src=\"talk/problems_ishak.jpg\" width=\"700px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Problems : human labelling is slow and error-prone\n",
    "\n",
    "<img src=\"talk/operator_comparison.jpg\" width=\"800px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Computer-aided diagnosis - improving the manual process\n",
    "\n",
    "<img src=\"talk/cad_intro.jpg\" width=\"800px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Computer-aided diagnosis - automatic cell counting and contour extraction\n",
    "\n",
    "<img src=\"talk/cad.jpg\" width=\"800px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Computer-aided diagnosis - tissue segmentation\n",
    "\n",
    "<img src=\"talk/cad2.jpg\" width=\"800px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Application - liver in Soay sheep\n",
    "\n",
    "<img src=\"talk/soaysheep.jpg\" width=\"800px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Liver structure\n",
    "\n",
    "<img src=\"talk/liver.jpg\" width=\"700px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Measuring levels of fibrosis, traditionally\n",
    "\n",
    "<img src=\"talk/ishak.png\" width=\"700px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The problem - quantifying the extent of inflammation\n",
    "\n",
    "<img src=\"talk/widefield_human_mask.jpg\" width=\"900px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A traditional image processing approach\n",
    "\n",
    "We're going to pull primarily from [scikit-image](http://scikit-image.org), a fantastic Python library for image processing. \n",
    "\n",
    "We'll also use parts of [scipy](https://www.scipy.org/)'s `ndimage` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Much like in other areas of traditional machine learning, a lot of image processing is about *feature engineering*, representing the information you have in a way that is more digestable and processable by a computer. Feature engineering is as much art as science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import maximum_filter, binary_fill_holes, distance_transform_edt, label\n",
    "from skimage import io, morphology, filters, exposure, color, transform, measure, feature, img_as_float\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Colour deconvolution matrix\n",
    "colour_deconv_matrix = np.linalg.inv([\n",
    "    [.26451728, .5205347, .81183386],\n",
    "    [.9199094, .29797825, .25489032],\n",
    "    [.28947765, .80015373, .5253158]\n",
    "])\n",
    "\n",
    "# Plot images in a single figure\n",
    "def plot_image(image, titles=None):\n",
    "    \n",
    "    image = image\n",
    "    \n",
    "    # When provided a single-channel image, ensure scaling and plot it as-is\n",
    "    if len(image.shape) == 2:\n",
    "        \n",
    "        # Rescale the image if needed\n",
    "        image = image.astype(float)\n",
    "        if image.max() > 1 or image.min() < 0:\n",
    "            image -= image.min()\n",
    "            image /= image.max()\n",
    "            \n",
    "        # Display the image without axes\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        io.imshow(image)\n",
    "        plt.gca().get_yaxis().set_visible(False)\n",
    "        plt.gca().get_xaxis().set_visible(False)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "    # When provided with a 3-channel image, plot the original, then separate the channels\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "\n",
    "        # Rescale the image if needed\n",
    "        if image.max() > 1 or image.min() < 0:\n",
    "            image -= image.min()\n",
    "            image /= image.max()\n",
    "            \n",
    "        # Display the image without axes\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        plt.subplot(1, 4, 1)\n",
    "        io.imshow(image)\n",
    "        plt.title(\"All channels\")\n",
    "        plt.gca().get_yaxis().set_visible(False)\n",
    "        plt.gca().get_xaxis().set_visible(False)\n",
    "\n",
    "        # Display its channels separately\n",
    "        for i in range(3):\n",
    "            \n",
    "            channel = image[:, :, i]\n",
    "            if channel.max() > 1 or channel.min() < 0:\n",
    "                channel -= channel.min()\n",
    "                channel /= channel.max()\n",
    "                \n",
    "            plt.subplot(1, 4, i+2)\n",
    "            io.imshow(channel)\n",
    "            plt.title(\"Channel {}\".format(i+1))\n",
    "            plt.gca().get_yaxis().set_visible(False)\n",
    "            plt.gca().get_xaxis().set_visible(False)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "    # When provided with an N-channel image, plot the first three channels as RGB and the rest separately\n",
    "    elif len(image.shape) == 3 and image.shape[2] > 3:\n",
    "        \n",
    "        n_channels = image.shape[2]\n",
    "    \n",
    "        # Rescale the images if needed\n",
    "        main_image = image[:, :, :3]\n",
    "        channels = []\n",
    "        \n",
    "        if main_image.max() > 1 or main_image.min() < 0:\n",
    "            main_image -= main_image.min()\n",
    "            main_image /= main_image.max()\n",
    "            \n",
    "        for i in range(3, n_channels):\n",
    "            channel = image[:, :, i]\n",
    "            if channel.max() > 1 or channel.min() < 0:\n",
    "                channel -= channel.min()\n",
    "                channel /= channel.max()\n",
    "            channels.append(channel)\n",
    "                \n",
    "        # Display the image without axes\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        plt.subplot(1, n_channels-2, 1)\n",
    "        io.imshow(main_image)\n",
    "        if titles:\n",
    "            plt.title(titles[0])\n",
    "        plt.gca().get_yaxis().set_visible(False)\n",
    "        plt.gca().get_xaxis().set_visible(False)\n",
    "\n",
    "        # Display its channels separately\n",
    "        for idx, channel in enumerate(channels):\n",
    "            plt.subplot(1, n_channels-2, idx+2)\n",
    "            io.imshow(channel)\n",
    "            if titles:\n",
    "                plt.title(titles[idx+1])\n",
    "            plt.gca().get_yaxis().set_visible(False)\n",
    "            plt.gca().get_xaxis().set_visible(False)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "def plot_grid(images, titles):\n",
    "    \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    for i in range(4):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        io.imshow(images[i])\n",
    "        plt.title(titles[i])\n",
    "        plt.gca().get_yaxis().set_visible(False)\n",
    "        plt.gca().get_xaxis().set_visible(False)\n",
    "        \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data, and look for a hint of where to start first\n",
    "widefield_image_file = \"data/Sheep11-4x-77.jpg\"\n",
    "image = transform.rescale(io.imread(widefield_image_file), 0.25)\n",
    "\n",
    "plot_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The first channel is potentially promising, but those veins might cause issues. Instead of thinking about this in terms of RGB, maybe we can break the image up into its dyes : haematoxylin and eosin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Perform a colour deconvolution\n",
    "heu = color.separate_stains(image, colour_deconv_matrix).astype(float)\n",
    "\n",
    "plot_image(heu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The middle channel here looks like a good start. Let's boost the contrast and improve our dynamic range using histogram equalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Apply CLAHE on the haematoxylin channel\n",
    "rescaled = exposure.rescale_intensity(heu[:, :, 1], out_range=(0, 1))\n",
    "equalised_hist = exposure.equalize_adapthist(rescaled)\n",
    "\n",
    "plot_image(np.dstack((image, equalised_hist)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Haematoxylin dyes nuclei - and zones of inflammation of just high concentrations of cells, each of which contain a nucleus. We can now pretty easily pick out the zones of inflammation. Still, we need to differentiate between the inflammation and the background, which also contains lots of nuclei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Apply Gaussian blur\n",
    "blurred = filters.gaussian(equalised_hist, 7)\n",
    "\n",
    "plot_image(np.dstack((image, blurred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Applying a blur helped to even things out a little. We're at a point where the inflammation is quite bright, and the background is a medium grey. Let's crank up the contrast to stretch our dynamic range a little."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Sigmoid transform for contrast\n",
    "contrast = exposure.adjust_sigmoid(blurred, cutoff=0.6)\n",
    "\n",
    "plot_image(np.dstack((image, contrast)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This looks much more promising now. We're probably at a point where we can threshold again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Apply an adaptive threshold\n",
    "thresholded = contrast > filters.threshold_local(contrast, 351, offset=-0.1)\n",
    "\n",
    "plot_image(np.dstack((image, thresholded)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We now have something that matches fairly well. However, the contours of the inflammatory zones aren't very \"natural\", and the zones contain holes. We can clean this up using some morphological operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Use a maximum filter followed by a binary closing to fill any holes\n",
    "enlarged = maximum_filter(thresholded, 5)\n",
    "inflammation = morphology.closing(enlarged, morphology.disk(11))\n",
    "\n",
    "plot_image(np.dstack((image, inflammation)), titles=[\"Original\", \"Automated image processing\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Let's compare with our human expert's mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Load up the human mask and visualise everything together\n",
    "mask = transform.rescale(io.imread(\"data/Sheep11-4x-77.jpg_mask.jpg\"), 0.25)\n",
    "all_images = np.dstack((image, mask, inflammation))\n",
    "\n",
    "plot_image(all_images, titles=[\"Original\", \"Human-masked\", \"Automatic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Noisy data, and the need for robustness\n",
    "\n",
    "<img src=\"talk/widefield.jpg\" width=\"700px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How does this algorithm perform ?\n",
    "\n",
    "<img src=\"talk/results_widefield.jpg\" width=\"800px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Extension : a neural network approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a quick experiment with a type of neural network called a convolutional encoder-decoder. They're some of the state-of-the-art neural network architectures for *semantic segmentation* : breaking down images into different parts, based on their content.\n",
    "\n",
    "Over the weekend, I trained a ( very untuned ) convolutional encoder-decoder. Let's see what it can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's use a convolutional encoder-decoder network to find inflammatory zones\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"models/histo_convnet.hdf5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Use the convnet to find the inflammatory zones, and compare with our work so far\n",
    "nn_image = transform.rescale(image, 0.5)\n",
    "pred = model.predict(nn_image.reshape(1, *nn_image.shape)).squeeze()\n",
    "\n",
    "plot_grid((image, mask, inflammation, pred), [\"Original\", \"Human-masked\", \"Classical\", \"ConvNet\"])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
